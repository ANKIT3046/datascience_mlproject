{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlpday2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ANKIT3046/datascience_mlproject/blob/npl/nlpday2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmuxGGBLdsqy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk import stem\n",
        "from nltk.stem import PorterStemmer #for stemming\n",
        "from nltk.stem import WordNetLemmatizer # for lemma"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4HJcFLIdv8b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIIYYy9vd272",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# stemming\n",
        "port=PorterStemmer()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMQBTzSdebvv",
        "colab_type": "code",
        "outputId": "d2d05657-f102-4063-e99a-83d7b41dc7c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "#word supply\n",
        "import time\n",
        "for i in ['going','goes','gone','go','intelligent','intelligence','intelligently']:\n",
        "  print(port.stem(i))\n",
        "  time.sleep(1)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "go\n",
            "goe\n",
            "gone\n",
            "go\n",
            "intellig\n",
            "intellig\n",
            "intellig\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2sywvf3bqm8",
        "colab_type": "code",
        "outputId": "743eb3af-d364-4da0-c5e3-b14d4dd1a1ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XE-aJ8UfBp2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.tokenize import sent_tokenize,word_tokenize\n",
        "from nltk.stem import PorterStemmer,WordNetLemmatizer\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jja5dORoajdD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data='''\n",
        "\n",
        " hello world i am hera. waht is your name ,you are good\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZ884kWia2yo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tdata=word_tokenize(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Od1Vcb45a31E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "removedata=[i for i in tdata if i.lower() not in stopwords.words('english')]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uX5gV3mqb5dz",
        "colab_type": "code",
        "outputId": "758549dd-402b-417c-a754-4591415c117a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "removedata"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hello', 'world', 'hera', '.', 'waht', 'name', ',', 'good']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLgR0uVlb7UU",
        "colab_type": "code",
        "outputId": "8243a4ec-3e5a-477d-cea4-d95dd57a52ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# stemming\n",
        "pt=PorterStemmer()\n",
        "for i in removedata:\n",
        "  print(i,\"stemmed into..>\",pt.stem(i))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hello stemmed into..> hello\n",
            "world stemmed into..> world\n",
            "hera stemmed into..> hera\n",
            ". stemmed into..> .\n",
            "waht stemmed into..> waht\n",
            "name stemmed into..> name\n",
            ", stemmed into..> ,\n",
            "good stemmed into..> good\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58IYpsIicNjQ",
        "colab_type": "code",
        "outputId": "1a3d741f-1c3f-4e18-d16a-167d39721065",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# lemma\n",
        "nltk.download('wordnet')\n",
        "wl=WordNetLemmatizer()\n",
        "for i in removedata:\n",
        "  print(wl.lemmatize(i))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "hello\n",
            "world\n",
            "hera\n",
            ".\n",
            "waht\n",
            "name\n",
            ",\n",
            "good\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ei3d9UQJdEzW",
        "colab_type": "code",
        "outputId": "cbe9bf25-db1d-49e4-a2f3-119fbbd9840e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#stem\n",
        "x='loving'\n",
        "pt=PorterStemmer()\n",
        "pt.stem(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'love'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "404Ufw3qdcFJ",
        "colab_type": "code",
        "outputId": "6d8af903-c640-4787-dd67-076f459fe651",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#lemm\n",
        "wl=WordNetLemmatizer()\n",
        "wl.lemmatize(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'loving'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r68Rxpt5dvJz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-JMMILaeZQQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# languge loading ->en\n",
        "nlp=spacy.load('en')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrU_FNyDemlW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data='''hello world this is ankit kumar. i am learning ok ok machine learning.\n",
        "i am in jaipur. but did't get time to explore jaipur,but definetly when i am free\n",
        "i do ?\n",
        "hi guys my'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6M5HFatfgC3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_data=nlp(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6KtLdFEfjuN",
        "colab_type": "code",
        "outputId": "ae6359e9-53b2-49d6-85d4-ecd52065b3b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for i in new_data:\n",
        "  print(i,'  ||||lemmatiztion of word is -->',i.lemma_)\n",
        "  print('####################################')\n",
        "  print(i,\"POS \",i.pos_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hello   ||||lemmatiztion of word is --> hello\n",
            "####################################\n",
            "hello POS  INTJ\n",
            "world   ||||lemmatiztion of word is --> world\n",
            "####################################\n",
            "world POS  NOUN\n",
            "this   ||||lemmatiztion of word is --> this\n",
            "####################################\n",
            "this POS  DET\n",
            "is   ||||lemmatiztion of word is --> be\n",
            "####################################\n",
            "is POS  VERB\n",
            "ankit   ||||lemmatiztion of word is --> ankit\n",
            "####################################\n",
            "ankit POS  ADJ\n",
            "kumar   ||||lemmatiztion of word is --> kumar\n",
            "####################################\n",
            "kumar POS  NOUN\n",
            ".   ||||lemmatiztion of word is --> .\n",
            "####################################\n",
            ". POS  PUNCT\n",
            "i   ||||lemmatiztion of word is --> i\n",
            "####################################\n",
            "i POS  PRON\n",
            "am   ||||lemmatiztion of word is --> be\n",
            "####################################\n",
            "am POS  VERB\n",
            "learning   ||||lemmatiztion of word is --> learn\n",
            "####################################\n",
            "learning POS  VERB\n",
            "ok   ||||lemmatiztion of word is --> ok\n",
            "####################################\n",
            "ok POS  INTJ\n",
            "ok   ||||lemmatiztion of word is --> ok\n",
            "####################################\n",
            "ok POS  INTJ\n",
            "machine   ||||lemmatiztion of word is --> machine\n",
            "####################################\n",
            "machine POS  NOUN\n",
            "learning   ||||lemmatiztion of word is --> learning\n",
            "####################################\n",
            "learning POS  NOUN\n",
            ".   ||||lemmatiztion of word is --> .\n",
            "####################################\n",
            ". POS  PUNCT\n",
            "\n",
            "   ||||lemmatiztion of word is --> \n",
            "\n",
            "####################################\n",
            "\n",
            " POS  SPACE\n",
            "i   ||||lemmatiztion of word is --> i\n",
            "####################################\n",
            "i POS  PRON\n",
            "am   ||||lemmatiztion of word is --> be\n",
            "####################################\n",
            "am POS  VERB\n",
            "in   ||||lemmatiztion of word is --> in\n",
            "####################################\n",
            "in POS  ADP\n",
            "jaipur   ||||lemmatiztion of word is --> jaipur\n",
            "####################################\n",
            "jaipur POS  NOUN\n",
            ".   ||||lemmatiztion of word is --> .\n",
            "####################################\n",
            ". POS  PUNCT\n",
            "but   ||||lemmatiztion of word is --> but\n",
            "####################################\n",
            "but POS  CCONJ\n",
            "did't   ||||lemmatiztion of word is --> did't\n",
            "####################################\n",
            "did't POS  NOUN\n",
            "get   ||||lemmatiztion of word is --> get\n",
            "####################################\n",
            "get POS  VERB\n",
            "time   ||||lemmatiztion of word is --> time\n",
            "####################################\n",
            "time POS  NOUN\n",
            "to   ||||lemmatiztion of word is --> to\n",
            "####################################\n",
            "to POS  PART\n",
            "explore   ||||lemmatiztion of word is --> explore\n",
            "####################################\n",
            "explore POS  VERB\n",
            "jaipur   ||||lemmatiztion of word is --> jaipur\n",
            "####################################\n",
            "jaipur POS  NOUN\n",
            ",   ||||lemmatiztion of word is --> ,\n",
            "####################################\n",
            ", POS  PUNCT\n",
            "but   ||||lemmatiztion of word is --> but\n",
            "####################################\n",
            "but POS  CCONJ\n",
            "definetly   ||||lemmatiztion of word is --> definetly\n",
            "####################################\n",
            "definetly POS  ADV\n",
            "when   ||||lemmatiztion of word is --> when\n",
            "####################################\n",
            "when POS  ADV\n",
            "i   ||||lemmatiztion of word is --> i\n",
            "####################################\n",
            "i POS  PRON\n",
            "am   ||||lemmatiztion of word is --> be\n",
            "####################################\n",
            "am POS  VERB\n",
            "free   ||||lemmatiztion of word is --> free\n",
            "####################################\n",
            "free POS  ADJ\n",
            "\n",
            "   ||||lemmatiztion of word is --> \n",
            "\n",
            "####################################\n",
            "\n",
            " POS  SPACE\n",
            "i   ||||lemmatiztion of word is --> i\n",
            "####################################\n",
            "i POS  PRON\n",
            "do   ||||lemmatiztion of word is --> do\n",
            "####################################\n",
            "do POS  VERB\n",
            "?   ||||lemmatiztion of word is --> ?\n",
            "####################################\n",
            "? POS  PUNCT\n",
            "\n",
            "   ||||lemmatiztion of word is --> \n",
            "\n",
            "####################################\n",
            "\n",
            " POS  SPACE\n",
            "hi   ||||lemmatiztion of word is --> hi\n",
            "####################################\n",
            "hi POS  INTJ\n",
            "guys   ||||lemmatiztion of word is --> guy\n",
            "####################################\n",
            "guys POS  NOUN\n",
            "my   ||||lemmatiztion of word is --> -PRON-\n",
            "####################################\n",
            "my POS  DET\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFVaOYigfqGz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}